{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True} client=<openai.resources.chat.completions.completions.Completions object at 0x00000210D4A5DD10> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000210D4A5E0D0> root_client=<openai.OpenAI object at 0x00000210D4A5D950> root_async_client=<openai.AsyncOpenAI object at 0x00000210D4A5DE50> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********') stream_usage=True\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    }
   ],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What latest news in Gen AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='As of the latest updates in 2023, several significant trends and developments have been occurring in the field of Generative AI (Gen AI):\\n\\n1. **Advancements in Models**: There has been a continued improvement in the capabilities of large language models (LLMs), with companies like OpenAI, Google, and Anthropic releasing more sophisticated versions that can handle complex tasks with enhanced proficiency and accuracy.\\n\\n2. **Open Source Models**: Alongside proprietary models, there has been a surge in the development and release of open-source generative models. These alternatives are gaining popularity as they allow for broader collaboration and customization by the research community.\\n\\n3. **Combination of Multimodal Capabilities**: Models that can handle and integrate multiple types of data, such as text, image, video, and audio, are becoming more prevalent. These multimodal models can provide more versatile and contextually aware outputs.\\n\\n4. **Ethical and Regulatory Focus**: There is increasing attention on the ethical implications and biases inherent in Gen AI systems. Discussions are ongoing about regulatory measures to ensure responsible use, transparency, and accountability in AI development and deployment.\\n\\n5. **Industry Adoption**: Businesses across various sectors, from finance to entertainment, are increasingly adopting Gen AI to innovate processes, create content, enhance customer experiences, and drive efficiency.\\n\\n6. **AI in Creativity**: Gen AI is being used in creative industries to develop music, art, and literature, pushing the boundaries of what AI-generated content can achieve and how it complements human creativity.\\n\\n7. **Human-AI Collaboration**: There is a growing focus on designing AI systems that can work collaboratively with humans, enhancing human decision-making and productivity rather than replacing human roles.\\n\\n8. **Continuous Learning and Adaptation**: The field is moving toward models capable of continuous learning from new data inputs, allowing for dynamic adaptation and improvement over time.\\n\\nThese trends highlight the rapid evolution and integration of Gen AI technologies across various domains, accompanied by ongoing discussions about their societal impact.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 404, 'prompt_tokens': 14, 'total_tokens': 418, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_deacdd5f6f', 'id': 'chatcmpl-CzGEVymeH2vVDgcZtrsNT8NwoagQ8', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019bcfb7-1d9a-74b0-b3ce-01640bc680b0-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 14, 'output_tokens': 404, 'total_tokens': 418, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Certainly! Langsmith is a tool developed by Langchain, designed to enhance the development and deployment of AI applications that utilize large language models (LLMs) and chains. It provides developers with robust capabilities for tracing, debugging, and testing LLM applications. Key features of Langsmith include:\\n\\n1. **Tracing**: It allows developers to capture detailed execution traces of their applications, which can be invaluable for understanding how data flows through the application and identifying where things might be going wrong.\\n\\n2. **Instrumentation**: You can embed instrumentation within your applications to gather insights about their performance and behavior. This is crucial for optimizing LLM-based applications and understanding their operational characteristics.\\n\\n3. **Testing and Evaluation**: Langsmith provides tools for rigorous testing of language model outputs and application logic. This includes automated testing frameworks and support for defining and measuring evaluation metrics to ensure that applications meet their expected performance criteria.\\n\\n4. **Integration**: Langsmith integrates seamlessly with Langchain, making it easier to manage complex workflows and interactions that typical language model applications involve.\\n\\nOverall, Langsmith is aimed at making the process of developing, testing, and deploying LLM applications more reliable and streamlined, especially for those working within the Langchain ecosystem.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 245, 'prompt_tokens': 33, 'total_tokens': 278, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_deacdd5f6f', 'id': 'chatcmpl-CzGEeLSNEZWBr5oqZBaoErId5vNgf', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019bcfb7-3a47-7c32-9558-31eb882cd156-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 33, 'output_tokens': 245, 'total_tokens': 278, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Certainly! Langsmith is a tool developed by Langchain, designed to enhance the development and deployment of AI applications that utilize large language models (LLMs) and chains. It provides developers with robust capabilities for tracing, debugging, and testing LLM applications. Key features of Langsmith include:\\n\\n1. **Tracing**: It allows developers to capture detailed execution traces of their applications, which can be invaluable for understanding how data flows through the application and identifying where things might be going wrong.\\n\\n2. **Instrumentation**: You can embed instrumentation within your applications to gather insights about their performance and behavior. This is crucial for optimizing LLM-based applications and understanding their operational characteristics.\\n\\n3. **Testing and Evaluation**: Langsmith provides tools for rigorous testing of language model outputs and application logic. This includes automated testing frameworks and support for defining and measuring evaluation metrics to ensure that applications meet their expected performance criteria.\\n\\n4. **Integration**: Langsmith integrates seamlessly with Langchain, making it easier to manage complex workflows and interactions that typical language model applications involve.\\n\\nOverall, Langsmith is aimed at making the process of developing, testing, and deploying LLM applications more reliable and streamlined, especially for those working within the Langchain ecosystem.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a suite of developer tools and infrastructure services designed to enhance applications built with large language models (LLMs). Developed by the creators of LangChain, Langsmith focuses on providing robust debugging, testing, and monitoring capabilities tailored for LLM-based applications. \n",
      "\n",
      "Some key features include:\n",
      "\n",
      "1. **Tracing and Debugging**: Langsmith offers tools to trace the execution of LLM applications and debug them effectively. By capturing detailed execution traces, developers can identify issues and optimize their models.\n",
      "\n",
      "2. **Testing**: It provides infrastructure for unit and integration testing of applications, ensuring that they behave as expected. This is crucial for maintaining reliability as the application evolves.\n",
      "\n",
      "3. **Monitoring and Analytics**: Langsmith enables developers to monitor applications in production, offering insights into usage patterns and performance metrics. This helps in scaling applications efficiently and ensuring they meet user expectations.\n",
      "\n",
      "4. **Version Control and Experimentation**: Developers can keep track of different versions of their models and the associated prompts. Langsmith supports experimentation, allowing for comparisons between different configurations to determine the most effective setup.\n",
      "\n",
      "Langsmith essentially combines these tools to streamline the development lifecycle of applications that leverage LLMs, making it easier for developers to build, test, and maintain sophisticated AI-powered applications.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
